@article{ahmadi2017survey,
  title={A survey of healthcare facility location},
  author={Ahmadi-Javid, Amir and Seyedi, Pardis and Syam, Siddhartha S},
  journal={Computers \& Operations Research},
  volume={79},
  pages={223--263},
  year={2017},
  publisher={Elsevier}
}

@article{rahimiandistributionally,
  title={Distributionally Robust Optimization with Decision-Dependent Polyhedral Ambiguity},
  author={Rahimian, Hamed and Mehrotra, Sanjay},
  year={2024},
}

@article{basciftci2024adaptive,
  title={Adaptive two-stage stochastic programming with an analysis on capacity expansion planning problem},
  author={Basciftci, Beste and Ahmed, Shabbir and Gebraeel, Nagi},
  journal={Manufacturing \& Service Operations Management},
  volume={26},
  number={6},
  pages={2121--2141},
  year={2024},
  publisher={INFORMS}
}

@article{borba2022optimizing,
  title={Optimizing police facility locations based on cluster analysis and the maximal covering location problem},
  author={Borba, Bruno Ferreira da Costa and de Gusm{\~a}o, Ana Paula Henriques and Clemente, Th{\'a}rcylla Rebecca Negreiros and Nepomuceno, Thyago Celso Cavalcante},
  journal={Applied System Innovation},
  volume={5},
  number={4},
  pages={74},
  year={2022},
  publisher={MDPI}
}

@article{pawlak_synthesis_2019,
	title = {Synthesis of {Mathematical} {Programming} models with one-class evolutionary strategies},
	volume = {44},
	issn = {2210-6502},
	url = {https://www.sciencedirect.com/science/article/pii/S2210650217305849},
	doi = {10.1016/j.swevo.2018.04.007},
	abstract = {We propose an Evolutionary Strategy-based One Class Constraint Synthesis (ESOCCS), a novel method for computer-assisted synthesis of constraints for Mathematical Programming models. ESOCCS synthesizes constraints of Linear Programming and Non-Linear Programming types using solely examples of feasible states of the modeled entity. This is a crucial feature from the viewpoint of modeling real-world business processes from data, as acquisition of examples of feasible states is straightforward for a normally operating process, while infeasible states corresponding to errors and faults are avoided in practice and thus uncommon. ESOCCS is verified on a suite of synthetic benchmarks having known model representations and synthesizes models with noticeable fidelity to the known representations in terms of syntax and semantics. We employ ESOCCS and an off-the-shelf solver in a fully automated setup for modeling and optimization of a real-world business process of rice production. The resulting optimal parameters of production are validated in the context of three exemplary rice farms. Likely increase in profit thanks to applying those parameters is concluded.},
	journal = {Swarm and Evolutionary Computation},
	author = {Pawlak, Tomasz P.},
	month = feb,
	year = {2019},
	keywords = {Constraint acquisition, Distribution, Linear Programming, Model induction, Quadratic Programming, Set Cover},
	pages = {335--348},
	file = {PDF:/home/gabriel/Zotero/storage/SYGYBZH9/Pawlak - 2019 - Synthesis of Mathematical Programming models with one-class evolutionary strategies.pdf:application/pdf},
}

@article{kudla_one-class_2018,
	title = {One-class synthesis of constraints for {Mixed}-{Integer} {Linear} {Programming} with {C4}.5 decision trees},
	volume = {68},
	issn = {1568-4946},
	url = {https://www.sciencedirect.com/science/article/pii/S1568494618301479},
	doi = {10.1016/j.asoc.2018.03.025},
	abstract = {We propose Constraint Synthesis with C4.5 (CSC4.5), a novel method for automated construction of constraints for Mixed-Integer Linear Programming (MILP) models from data. Given a sample of feasible states of a modeled entity, e.g., a business process or a system, CSC4.5 synthesizes a well-formed MILP model of that entity, suitable for simulation and optimization using an off-the-shelf solver. CSC4.5 operates by estimating the distribution of the feasible states, bounding that distribution with C4.5 decision tree and transforming that tree into a MILP model. We verify CSC4.5 experimentally using parameterized synthetic benchmarks, and conclude considerable fidelity of the synthesized constraints to the actual constraints in the benchmarks. Next, we apply CSC4.5 to synthesize from past observations two MILP models of a real-world business process of wine production, optimize the MILP models using an external solver and validate the optimal solutions with use of a competing modeling method.},
	journal = {Applied Soft Computing},
	author = {Kudła, Patryk and Pawlak, Tomasz P.},
	month = jul,
	year = {2018},
	keywords = {Business process, Constraint synthesis, Mathematical programming, Model acquisition, One-class classification},
	pages = {1--12},
	file = {PDF:/home/gabriel/Zotero/storage/M8RFSBSL/Kudła and Pawlak - 2018 - One-class synthesis of constraints for Mixed-Integer Linear Programming with C4.5 decision trees.pdf:application/pdf},
}

@article{fajemisin_optimization_2024,
	title = {Optimization with constraint learning: {A} framework and survey},
	volume = {314},
	issn = {0377-2217},
	url = {https://www.sciencedirect.com/science/article/pii/S0377221723003405},
	doi = {10.1016/j.ejor.2023.04.041},
	abstract = {Many real-life optimization problems frequently contain one or more constraints or objectives for which there are no explicit formulae. If however data on feasible and/or infeasible states are available, these data can be used to learn the constraints. The benefits of this approach are clearly seen, however, there is a need for this process to be carried out in a structured manner. This paper, therefore, provides a framework for Optimization with Constraint Learning (OCL) which we believe will help to formalize and direct the process of learning constraints from data. This framework includes the following steps: (i) setup of the conceptual optimization model, (ii) data gathering and preprocessing, (iii) selection and training of predictive models, (iv) resolution of the optimization model, and (v) verification and improvement of the optimization model. We then review the recent OCL literature in light of this framework and highlight current trends, as well as areas for future research.},
	number = {1},
	journal = {European Journal of Operational Research},
	author = {Fajemisin, Adejuyigbe O. and Maragno, Donato and den Hertog, Dick},
	month = apr,
	year = {2024},
	keywords = {Analytics, Constraint learning, Machine learning, Optimization},
	pages = {1--14},
	file = {PDF:/home/gabriel/Zotero/storage/K7MSBW6N/Fajemisin et al. - 2024 - Optimization with constraint learning A framework and survey.pdf:application/pdf},
}

@article{bertsimas_predictive_2020,
	title = {From {Predictive} to {Prescriptive} {Analytics}},
	volume = {66},
	issn = {0025-1909},
	url = {https://doi.org/10.1287/mnsc.2018.3253},
	doi = {10.1287/mnsc.2018.3253},
	abstract = {We combine ideas from machine learning (ML) and operations research and management science (OR/MS) in developing a framework, along with specific methods, for using data to prescribe optimal decisions in OR/MS problems. In a departure from other work on data-driven optimization, we consider data consisting, not only of observations of quantities with direct effect on costs/revenues, such as demand or returns, but also predominantly of observations of associated auxiliary quantities. The main problem of interest is a conditional stochastic optimization problem, given imperfect observations, where the joint probability distributions that specify the problem are unknown. We demonstrate how our proposed methods are generally applicable to a wide range of decision problems and prove that they are computationally tractable and asymptotically optimal under mild conditions, even when data are not independent and identically distributed and for censored observations. We extend these to the case in which some decision variables, such as price, may affect uncertainty and their causal effects are unknown. We develop the coefficient of prescriptiveness P to measure the prescriptive content of data and the efficacy of a policy from an operations perspective. We demonstrate our approach in an inventory management problem faced by the distribution arm of a large media company, shipping 1 billion units yearly. We leverage both internal data and public data harvested from IMDb, Rotten Tomatoes, and Google to prescribe operational decisions that outperform baseline measures. Specifically, the data we collect, leveraged by our methods, account for an 88\% improvement as measured by our coefficient of prescriptiveness.This paper was accepted by Noah Gans, optimization.},
	number = {3},
	urldate = {2024-09-21},
	journal = {Management Science},
	author = {Bertsimas, Dimitris and Kallus, Nathan},
	month = mar,
	year = {2020},
	note = {Publisher: INFORMS},
	pages = {1025--1044},
	annote = {doi: 10.1287/mnsc.2018.3253},
	file = {PDF:/home/gabriel/Zotero/storage/9L6B2U8D/Bertsimas and Kallus - 2020 - From Predictive to Prescriptive Analytics.pdf:application/pdf},
}

@article{munch_algorithmic_2024,
	title = {Algorithmic decision-making: {The} right to explanation and the significance of stakes},
	volume = {11},
	issn = {2053-9517},
	url = {https://doi.org/10.1177/20539517231222872},
	doi = {10.1177/20539517231222872},
	abstract = {The stakes associated with an algorithmic decision are often said to play a role in determining whether the decision engenders a right to an explanation. More specifically, ?high stakes? decisions are often said to engender such a right to explanation whereas ?low stakes? or ?non-high? stakes decisions do not. While the overall gist of these ideas is clear enough, the details are lacking. In this paper, we aim to provide these details through a detailed investigation of what we will call the ?Simple Stakes Thesis.? The Simple Stakes Thesis, as it will turn out, is too simple. For even if the stakes associated with a specific one-off decision are low?and hence does not engender a right to an explanation?such decisions may nevertheless form part of a high stakes pattern or aggregate of decisions. In such cases, we argue, even a low stakes decision may engender a right to explanation. Not only does this show that the right to explanation is more demanding than so far recognized but it also shows that the stakes thesis is significantly harder to apply in practice.},
	number = {1},
	urldate = {2024-09-21},
	journal = {Big Data \& Society},
	author = {Munch, Lauritz Aastrup and Bjerring, Jens Christian and Mainz, Jakob Thrane},
	month = mar,
	year = {2024},
	note = {Publisher: SAGE Publications Ltd},
	pages = {20539517231222872},
	annote = {doi: 10.1177/20539517231222872},
	file = {PDF:/home/gabriel/Zotero/storage/WH6RH68B/Munch et al. - 2024 - Algorithmic decision-making The right to explanation and the significance of stakes.pdf:application/pdf},
}

@article{wachter_counterfactual_2017,
	title = {Counterfactual {Explanations} {Without} {Opening} the {Black} {Box}: {Automated} {Decisions} and the {GDPR}},
	issn = {1556-5068},
	shorttitle = {Counterfactual {Explanations} {Without} {Opening} the {Black} {Box}},
	url = {https://www.ssrn.com/abstract=3063289},
	doi = {10.2139/ssrn.3063289},
	language = {en},
	urldate = {2024-09-21},
	journal = {SSRN Electronic Journal},
	author = {Wachter, Sandra and Mittelstadt, Brent and Russell, Chris},
	year = {2017},
	file = {PDF:/home/gabriel/Zotero/storage/Q75LI7VC/Wachter et al. - 2017 - Counterfactual Explanations Without Opening the Black Box Automated Decisions and the GDPR.pdf:application/pdf},
}

@article{kim_why_2022,
	title = {Why a {Right} to an {Explanation} of {Algorithmic} {Decision}-{Making} {Should} {Exist}: {A} {Trust}-{Based} {Approach}},
	volume = {32},
	issn = {1052-150X},
	url = {https://www.cambridge.org/core/product/C620A6A5FCB781384D20E08BE4CD09BC},
	doi = {10.1017/beq.2021.3},
	abstract = {Businesses increasingly rely on algorithms that are data-trained sets of decision rules (i.e., the output of the processes often called “machine learning”) and implement decisions with little or no human intermediation. In this article, we provide a philosophical foundation for the claim that algorithmic decision-making gives rise to a “right to explanation.” It is often said that, in the digital era, informed consent is dead. This negative view originates from a rigid understanding that presumes informed consent is a static and complete transaction. Such a view is insufficient, especially when data are used in a secondary, noncontextual, and unpredictable manner—which is the inescapable nature of advanced artificial intelligence systems. We submit that an alternative view of informed consent—as an assurance of trust for incomplete transactions—allows for an understanding of why the rationale of informed consent already entails a right to ex post explanation.},
	number = {1},
	journal = {Business Ethics Quarterly},
	author = {Kim, Tae Wan and Routledge, Bryan R.},
	year = {2022},
	note = {Edition: 2021/05/05
Publisher: Cambridge University Press},
	keywords = {a right to explanation, artificial intelligence ethics, California Consumer Privacy Act (CCPA), explainable AI (XAI), General Data Protection Regulation (GDPR), online privacy},
	pages = {75--102},
	file = {PDF:/home/gabriel/Zotero/storage/DFX7M68H/Kim and Routledge - 2022 - Why a Right to an Explanation of Algorithmic Decision-Making Should Exist A Trust-Based Approach.pdf:application/pdf},
}

@phdthesis{trites_black_2019,
	type = {Thesis},
	title = {Black {Box} {Ethics}: {Why} the {Rights} to {Explanation} and to be {Forgotten} are {Ethically} {Critical} {Components} for {Vulnerable} {Populations}},
	url = {http://dx.doi.org/10.20381/ruor-23374},
	abstract = {Automated decision-making systems are becoming more and more prevalent in our society. These systems are often purported by their developers to remove human bias from decision-making in a variety of sectors from financial systems (e.g., credit card and mortgage applications) to Human Resources (e.g., screening resumes and matching competencies for employers). While the assertion of bias reduction is a commonly cited benefits of these automated decision-making systems, recent research and scandals in the news demonstrate that it is not safe to assume that these systems are free from bias. There is a growing body of evidence indicating that the algorithms informing automated decision-making systems are influenced by the fallible humans who develop them. The result is that a range of biases is being observed in the field of automated decision-making: from feedback loops built into algorithms where data are collected that support existing theories, to racial discrimination — knowingly (overt discrimination) or unknowingly (social assumptions). This creates a new reality in which biases are potentially just as prevalent in algorithm-made decisions as in human-made decisions. The risks to citizens, however, may be heightened due to the incorrect assumption that these algorithms are unbiased. The cloaked nature — and increasing omnipotence of — algorithms adds a further level of complexity to this situation. Many algorithms are developed by private companies and individuals who which cite proprietary rights — or ‘trade secrets’ — as protections and justifications for confidentiality around their algorithms. These rights enable developers to keep the rationales used for making decisions, built into the algorithms, in a ‘black box’. This black box shields the algorithms and their resulting decisions away from scrutiny and criticism. As a result, citizens, governments and other advocates are unable to fully assess the algorithms and their impact on societies. This thesis will do the following: the situation around and important concepts in Artificial Intelligence (AI) and Automated Decision-Making Systems (ADMS) will be introduced and defined, focusing on Black box algorithms and the problems surrounding these systems. From here, the case study will be introduced, introducing the reader to specific aspects of the concerns around black box algorithms, as an example to be kept in mind for the remainder of the thesis, culminating in the subsequent analysis at the end of the paper. Following this, a feminist bioethical framework on vulnerability and consent will be outlined and reviewed. After the introduction of the case study and proposed framework, current Canadian legislation surrounding data collection and privacy will be reviewed, specifically the Personal Information Protection and Electronic Documents Act (PIPEDA) and a working paper from the Office of the Privacy Commissioner of Canada, providing the reader a Canadian-based context. Next, the concepts of the RtE and then the RtbF will be introduced and discussed in relation to the collection and storage of personal information. At this point, an analysis will be conducted, bridging the RtE and the RtbF with the feminist bioethical framework on vulnerability and consent and culminating in a discussion on and a revisiting of the case study. Using the case study, the paper will conclude how the RtE and the RtbF work to best support vulnerable populations and their ability to achieve autonomy and how the application could be adapted to best accommodate this objective.},
	language = {English},
	school = {Université Saint-Paul},
	author = {Trites, Allison},
	month = apr,
	year = {2019},
	file = {PDF:/home/gabriel/Zotero/storage/48M43RDG/Trites - 2019 - Black Box Ethics Why the Rights to Explanation and to be Forgotten are Ethically Critical Component.pdf:application/pdf},
}

@article{bertsimas_voice_2021,
	title = {The voice of optimization},
	volume = {110},
	issn = {1573-0565},
	url = {https://doi.org/10.1007/s10994-020-05893-5},
	doi = {10.1007/s10994-020-05893-5},
	abstract = {We introduce the idea that using optimal classification trees (OCTs) and optimal classification trees with-hyperplanes (OCT-Hs), interpretable machine learning algorithms developed by Bertsimas and Dunn (Mach Learn 106(7):1039–1082, 2017), we are able to obtain insight on the strategy behind the optimal solution in continuous and mixed-integer convex optimization problem as a function of key parameters that affect the problem. In this way, optimization is not a black box anymore. Instead, we redefine optimization as a multiclass classification problem where the predictor gives insights on the logic behind the optimal solution. In other words, OCTs and OCT-Hs give optimization a voice. We show on several realistic examples that the accuracy behind our method is in the 90–100\% range, while even when the predictions are not correct, the degree of suboptimality or infeasibility is very low. We compare optimal strategy predictions of OCTs and OCT-Hs and feedforward neural networks (NNs) and conclude that the performance of OCT-Hs and NNs is comparable. OCTs are somewhat weaker but often competitive. Therefore, our approach provides a novel insightful understanding of optimal strategies to solve a broad class of continuous and mixed-integer optimization problems.},
	language = {en},
	number = {2},
	urldate = {2024-09-21},
	journal = {Machine Learning},
	author = {Bertsimas, Dimitris and Stellato, Bartolomeo},
	month = feb,
	year = {2021},
	keywords = {Artificial Intelligence, Interpretability, Multiclass classification, Parametric optimization, Sampling},
	pages = {249--277},
	file = {Full Text PDF:/home/gabriel/Zotero/storage/86WAZRC4/Bertsimas and Stellato - 2021 - The voice of optimization.pdf:application/pdf},
}

@article{kaminski_right_2019,
	title = {The right to explanation, explained ({June} 15, 2018). {University} of {Colorado} {Law} {Legal} {Studies} {Research} {Paper} {No}. 18-24},
	volume = {34},
	number = {1},
	journal = {Berkeley Technology Law Journal},
	author = {Kaminski, Margot E.},
	year = {2019},
	file = {PDF:/home/gabriel/Zotero/storage/MX9H7PBA/Kaminski - 2019 - The right to explanation, explained (June 15, 2018). University of Colorado Law Legal Studies Resear.pdf:application/pdf},
}

@article{rios_multi-period_2015,
	title = {Multi-period forecasting and scenario generation with limited data},
	volume = {12},
	issn = {1619-6988},
	url = {https://doi.org/10.1007/s10287-015-0230-5},
	doi = {10.1007/s10287-015-0230-5},
	abstract = {Data for optimization problems often comes from (deterministic) forecasts, but it is naïve to consider a forecast as the only future possibility. A more sophisticated approach uses data to generate alternative future scenarios, each with an attached probability. The basic idea is to estimate the distribution of forecast errors and use that to construct the scenarios. Although sampling from the distribution of errors comes immediately to mind, we propose instead to approximate rather than sample. Benchmark studies show that the method we propose works well.},
	number = {2},
	journal = {Computational Management Science},
	author = {Rios, Ignacio and Wets, Roger J-B and Woodruff, David L.},
	month = apr,
	year = {2015},
	pages = {267--295},
	file = {PDF:/home/gabriel/Zotero/storage/AUHE9WGM/Rios et al. - 2015 - Multi-period forecasting and scenario generation with limited data.pdf:application/pdf},
}

@inproceedings{hannah_nonparametric_2010,
	title = {Nonparametric {Density} {Estimation} for {Stochastic} {Optimization} with an {Observable} {State} {Variable}},
	volume = {23},
	url = {https://proceedings.neurips.cc/paper_files/paper/2010/file/e1e32e235eee1f970470a3a6658dfdd5-Paper.pdf},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Hannah, Lauren and Powell, Warren and Blei, David},
	editor = {Lafferty, J. and Williams, C. and Shawe-Taylor, J. and Zemel, R. and Culotta, A.},
	year = {2010},
	file = {PDF:/home/gabriel/Zotero/storage/KR7L5JRA/Hannah et al. - 2010 - Nonparametric Density Estimation for Stochastic Optimization with an Observable State Variable.pdf:application/pdf},
}

@article{ban_big_2019,
	title = {The {Big} {Data} {Newsvendor}: {Practical} {Insights} from {Machine} {Learning}},
	volume = {67},
	issn = {0030-364X},
	url = {https://doi.org/10.1287/opre.2018.1757},
	doi = {10.1287/opre.2018.1757},
	abstract = {In Ban and Rudin?s (2018) ?The Big Data Newsvendor: Practical Insights from Machine Learning,? the authors take an innovative machine-learning approach to a classic problem solved by almost every company, every day, for inventory management. By allowing companies to use large amounts of data to predict the correct answers to decisions directly, they avoid intermediate questions, such as ?how many customers will we get tomorrow?? and instead can tell the company how much inventory to stock for these customers. This has implications for almost all other decision-making problems considered in operations research, which has traditionally considered data estimation separately from the decision optimization. Their proposed methods are shown to work both analytically and empirically with the latter explored in a hospital nurse staffing example in which the best one-step, feature-based newsvendor algorithm (the kernel-weights optimization method) is shown to beat the best-practice benchmark by 24\% in the out-of-sample cost at a fraction of the speed.},
	number = {1},
	urldate = {2024-09-19},
	journal = {Operations Research},
	author = {Ban, Gah-Yi and Rudin, Cynthia},
	month = jan,
	year = {2019},
	note = {Publisher: INFORMS},
	pages = {90--108},
	annote = {doi: 10.1287/opre.2018.1757},
}

@article{misic_data_2020,
	title = {Data {Analytics} in {Operations} {Management}: {A} {Review}},
	volume = {22},
	issn = {1523-4614},
	url = {https://doi.org/10.1287/msom.2019.0805},
	doi = {10.1287/msom.2019.0805},
	abstract = {Research in operations management has traditionally focused on models for understanding, mostly at a strategic level, how firms should operate. Spurred by the growing availability of data and recent advances in machine learning and optimization methodologies, there has been an increasing application of data analytics to problems in operations management. In this paper, we review recent applications of data analytics to operations management in three major areas?supply chain management, revenue management, and healthcare operations?and highlight some exciting directions for the future.},
	number = {1},
	urldate = {2024-09-19},
	journal = {Manufacturing \& Service Operations Management},
	author = {Mišić, Velibor V. and Perakis, Georgia},
	month = jan,
	year = {2020},
	note = {Publisher: INFORMS},
	pages = {158--169},
	annote = {doi: 10.1287/msom.2019.0805},
}

@article{basciftci_distributionally_2021,
	title = {Distributionally robust facility location problem under decision-dependent stochastic demand},
	volume = {292},
	issn = {03772217},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0377221720309449},
	doi = {10.1016/j.ejor.2020.11.002},
	abstract = {While the traditional facility location problem considers exogenous demand, in some applications, locations of facilities could affect the willingness of customers to use certain types of services, e.g., carsharing, and therefore they also affect realizations of random demand. Moreover, a decision maker may not know the exact distribution of such endogenous demand and how it is affected by location choices. In this paper, we consider a distributionally robust facility location problem, in which we interpret the moments of stochastic demand as functions of facility-location decisions. We reformulate a two-stage decisiondependent distributionally robust optimization model as a monolithic formulation, and then derive exact mixed-integer linear programming reformulation as well as valid inequalities when the means and variances of demand are piecewise linear functions of location solutions. We conduct extensive computational studies, in which we compare our model with a decision-dependent deterministic model, as well as stochastic programming and distributionally robust models without the decision-dependent assumption. The results show superior performance of our approach with remarkable improvement in proﬁt and quality of service under various settings, in addition to computational speed-ups given by formulation enhancements. These results draw attention to the need of considering the impact of location decisions on customer demand within this strategic-level planning problem.},
	language = {en},
	number = {2},
	urldate = {2024-09-19},
	journal = {European Journal of Operational Research},
	author = {Basciftci, Beste and Ahmed, Shabbir and Shen, Siqian},
	month = jul,
	year = {2021},
	pages = {548--561},
	file = {PDF:/home/gabriel/Zotero/storage/PGA7DGYF/Basciftci et al. - 2021 - Distributionally robust facility location problem under decision-dependent stochastic demand.pdf:application/pdf},
}

@article{ban_dynamic_2019,
	title = {Dynamic {Procurement} of {New} {Products} with {Covariate} {Information}: {The} {Residual} {Tree} {Method}},
	volume = {21},
	issn = {1523-4614},
	url = {https://doi.org/10.1287/msom.2018.0725},
	doi = {10.1287/msom.2018.0725},
	abstract = {Problem definition: We study the practice-motivated problem of dynamically procuring a new, short-life-cycle product under demand uncertainty. The firm does not know the demand for the new product but has data on similar products sold in the past, including demand histories and covariate information such as product characteristics. Academic/practical relevance: The dynamic procurement problem has long attracted academic and practitioner interest, and we solve it in an innovative data-driven way with proven theoretical guarantees. This work is also the first to leverage the power of covariate data in solving this problem. Methodology: We propose a new combined forecasting and optimization algorithm called the residual tree method and analyze its performance via epiconvergence theory and computations. Our method generalizes the classical scenario tree method by using covariates to link historical data on similar products to construct demand forecasts for the new product. Results: We prove, under fairly mild conditions, that the residual tree method is asymptotically optimal as the size of the data set grows. We also numerically validate the method for problem instances derived using data from the global fashion retailer Zara. We find that ignoring covariate information leads to systematic bias in the optimal solution, translating to a 6\%?15\% increase in the total cost for the problem instances under study. We also find that solutions based on trees using just two to three branches per node, which is common in the existing literature, are inadequate, resulting in 30\%?66\% higher total costs compared with our best solution. Managerial implications: The residual tree is a new and generalizable approach that uses past data on similar products to manage new product inventories. We also quantify the value of covariate information and of granular demand modeling.},
	number = {4},
	urldate = {2024-09-19},
	journal = {Manufacturing \& Service Operations Management},
	author = {Ban, Gah-Yi and Gallien, Jérémie and Mersereau, Adam J.},
	month = oct,
	year = {2019},
	note = {Publisher: INFORMS},
	pages = {798--815},
	annote = {doi: 10.1287/msom.2018.0725},
}

@article{rahimian_data-driven_2023,
	title = {Data-{Driven} {Approximation} of {Contextual} {Chance}-{Constrained} {Stochastic} {Programs}},
	volume = {33},
	url = {https://doi.org/10.1137/22M1528045},
	doi = {10.1137/22M1528045},
	abstract = {Abstract. Uncertainty in classical stochastic programming models is often described solely by independent random parameters, ignoring their dependence on multidimensional features. We describe a novel contextual chance-constrained programming formulation that incorporates features, and argue that solutions that do not take them into account may not be implementable. Our formulation cannot be solved exactly in most cases, and we propose a tractable and fully data-driven approximate model that relies on weighted sums of random variables. We obtain a stochastic lower bound for the optimal value and feasibility results that include convergence to the true feasible set as the number of data points increases, as well as the minimal number of data points needed to obtain a feasible solution with high probability. We illustrate our findings in a vaccine allocation problem and compare the results with a naïve sample average approximation approach.},
	number = {3},
	journal = {SIAM Journal on Optimization},
	author = {Rahimian, Hamed and Pagnoncelli, Bernardo},
	year = {2023},
	note = {\_eprint: https://doi.org/10.1137/22M1528045},
	pages = {2248--2274},
	file = {PDF:/home/gabriel/Zotero/storage/JI4QR56D/Rahimian and Pagnoncelli - 2023 - Data-Driven Approximation of Contextual Chance-Constrained Stochastic Programs.pdf:application/pdf},
}

@inproceedings{chenreddy_data-driven_2022,
	title = {Data-{Driven} {Conditional} {Robust} {Optimization}},
	volume = {35},
	url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/3df874367ce2c43891aab1ab23ae6959-Paper-Conference.pdf},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Chenreddy, Abhilash Reddy and Bandi, Nymisha and Delage, Erick},
	editor = {Koyejo, S. and Mohamed, S. and Agarwal, A. and Belgrave, D. and Cho, K. and Oh, A.},
	year = {2022},
	pages = {9525--9537},
	file = {PDF:/home/gabriel/Zotero/storage/W44CTTED/Chenreddy et al. - 2022 - Data-Driven Conditional Robust Optimization.pdf:application/pdf},
}

@article{theozzo_robust_2023,
	title = {A robust optimization framework for forest biorefineries design considering uncertainties on biomass growth and product selling prices},
	volume = {175},
	issn = {0098-1354},
	url = {https://www.sciencedirect.com/science/article/pii/S0098135423001266},
	doi = {10.1016/j.compchemeng.2023.108256},
	abstract = {The dependence of biomass growth on uncontrolled environmental factors and the lack of confidence in product selling price estimation imposes challenges for the efficient design of biorefineries, especially for forest systems, which present complex and long-termed growth behavior. The present work proposes the expansion of an optimization framework for forest biorefineries design to handle uncertainties on both biomass productivity and product selling prices. A robust formulation is proposed under a box and polyhedral uncertainty set formulation allowing its conservatism degree to be controlled. A case study of a eucalyptus biorefinery in Brazil illustrates the model's capabilities. The canonical worst-case approach to uncertainties on selling prices leads to a null optimal Net Present Value (NPV) and, on biomass growth, leads to a design that uses a 70\% excess of lands. Scenarios of a controlled degree of conservatism lead to designs closer to the uncertainty-free optimal NPV of 136 bi BRL.},
	urldate = {2024-09-18},
	journal = {Computers \& Chemical Engineering},
	author = {Theozzo, Bruno and Teles dos Santos, Moises},
	month = jul,
	year = {2023},
	keywords = {Biomass productivity uncertainty, Forest biorefinery, MILP, Price uncertainty, Pulp and Paper, Robust optimization},
	pages = {108256},
	file = {PDF:/home/gabriel/Zotero/storage/EIWT33IB/Theozzo and Teles dos Santos - 2023 - A robust optimization framework for forest biorefineries design considering uncertainties on biomass.pdf:application/pdf},
}

@article{nguyen_bridging_2023,
	title = {Bridging {Bayesian} and {Minimax} {Mean} {Square} {Error} {Estimation} via {Wasserstein} {Distributionally} {Robust} {Optimization}},
	volume = {48},
	issn = {0364-765X},
	url = {https://pubsonline.informs.org/doi/full/10.1287/moor.2021.1176},
	doi = {10.1287/moor.2021.1176},
	abstract = {We introduce a distributionally robust minimium mean square error estimation model with a Wasserstein ambiguity set to recover an unknown signal from a noisy observation. The proposed model can be viewed as a zero-sum game between a statistician choosing an estimator—that is, a measurable function of the observation—and a fictitious adversary choosing a prior—that is, a pair of signal and noise distributions ranging over independent Wasserstein balls—with the goal to minimize and maximize the expected squared estimation error, respectively. We show that, if the Wasserstein balls are centered at normal distributions, then the zero-sum game admits a Nash equilibrium, by which the players’ optimal strategies are given by an affine estimator and a normal prior, respectively. We further prove that this Nash equilibrium can be computed by solving a tractable convex program. Finally, we develop a Frank–Wolfe algorithm that can solve this convex program orders of magnitude faster than state-of-the-art general-purpose solvers. We show that this algorithm enjoys a linear convergence rate and that its direction-finding subproblems can be solved in quasi-closed form. Funding: This research was supported by the Swiss National Science Foundation [Grants BSCGI0\_ 157733 and 51NF40\_180545], an Early Postdoc.Mobility Fellowship [Grant P2ELP2\_195149], and the European Research Council [Grant TRUST-949796].},
	number = {1},
	urldate = {2024-09-18},
	journal = {Mathematics of Operations Research},
	author = {Nguyen, Viet Anh and Shafieezadeh-Abadeh, Soroosh and Kuhn, Daniel and Mohajerin Esfahani, Peyman},
	month = feb,
	year = {2023},
	note = {Publisher: INFORMS},
	keywords = {affine estimator, distributionally robust optimization, minimum mean square error estimation, Primary: 90-10, 90B99, Wasserstein distance},
	pages = {1--37},
	file = {Full Text PDF:/home/gabriel/Zotero/storage/M33AIZIR/Nguyen et al. - 2023 - Bridging Bayesian and Minimax Mean Square Error Estimation via Wasserstein Distributionally Robust O.pdf:application/pdf},
}

@article{lotfi_robust_2024,
	title = {Robust optimization of risk-aware, resilient and sustainable closed-loop supply chain network design with {Lagrange} relaxation and fix-and-optimize},
	volume = {27},
	issn = {1367-5567},
	url = {https://doi.org/10.1080/13675567.2021.2017418},
	doi = {10.1080/13675567.2021.2017418},
	abstract = {This study explores a Robust, Risk-aware, Resilient, and Sustainable Closed-Loop Supply Chain Network Design (3RSCLSCND) to tackle demand fluctuation like COVID-19 pandemic. A two-stage robust stochastic multiobjective programming model serves to express the proposed problems in formulae. The objective functions include minimising costs, CO2 emissions, energy consumption, and maximising employment by applying Conditional Value at Risk (CVaR) to achieve reliability through risk reduction. The Entropic Value at Risk (EVaR) and Minimax method are used to compare with the proposed model. We utilise the Lp-Metric method to solve the multiobjective problem. Since this model is complex, the Lagrange relaxation and Fix-and-Optimise algorithm are applied to find lower and upper bounds in large-scale, respectively. The results confirm the superior power of the model offered in estimating costs, energy consumption, environmental pollution, and employment level. This model and algorithms are applicable for other CLSC problems.},
	number = {5},
	urldate = {2024-09-18},
	journal = {International Journal of Logistics Research and Applications},
	author = {Lotfi, Reza and Sheikhi, Zohre and Amra, Mohsen and AliBakhshi, Mehdi and Weber, Gerhard-Wilhelm},
	month = may,
	year = {2024},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/13675567.2021.2017418},
	keywords = {Closed-loop supply chain, fix-and-optimize, Lagrangian relaxation, resiliency, risk, sustainability},
	pages = {705--745},
	file = {Full Text PDF:/home/gabriel/Zotero/storage/J2H73DCA/Lotfi et al. - 2024 - Robust optimization of risk-aware, resilient and sustainable closed-loop supply chain network design.pdf:application/pdf},
}

@article{sun_robust_2024,
	title = {A robust optimization approach for inventory management with limited-time discounts and service-level requirement under demand uncertainty},
	volume = {267},
	issn = {0925-5273},
	url = {https://www.sciencedirect.com/science/article/pii/S0925527323003286},
	doi = {10.1016/j.ijpe.2023.109096},
	abstract = {A multi-period inventory management problem is considered for a retailer offering limited-time discounts and having a joint service-level requirement over the discount periods under demand uncertainty. In each period, the retailer, only knowing a reference value and the bounds of the uncertain demand, has to determine the order quantity of the product before demand realizations to maximize the total profit over the planning horizon while achieving the required service level over the discount periods. A budgeted uncertainty set is adopted to accommodate demand uncertainty and a joint chance constraint is used to formulate the service-level requirement. The retailer problem is formulated as an affinely adjustable robust chance-constrained model and is transformed into a linear program. A double-layer iterative approach is proposed to solve the problem. The outer layer uses a posteriori method to update the budget coefficient. The inner layer solves the affinely adjustable robust chance-constrained model with the updated budget coefficient, and obtains the updated order quantities. A case study based on real data demonstrates that the proposed approach outperforms other approaches by better balancing the average realized profit and the realized service level. Moreover, the results show that the retailer can obtain a larger average realized profit by gradually than abruptly changing the prices.},
	urldate = {2024-09-18},
	journal = {International Journal of Production Economics},
	author = {Sun, Yimeng and Qiu, Ruozhen and Sun, Minghe},
	month = jan,
	year = {2024},
	keywords = {Adjustable robust optimization, Demand uncertainty, Inventory, Limited-time discount, Service level},
	pages = {109096},
	file = {PDF:/home/gabriel/Zotero/storage/FSJ2REZM/Sun et al. - 2024 - A robust optimization approach for inventory management with limited-time discounts and service-leve.pdf:application/pdf},
}

@article{georgantas_robust_2024,
	title = {Robust optimization approaches for portfolio selection: a comparative analysis},
	volume = {339},
	issn = {1572-9338},
	shorttitle = {Robust optimization approaches for portfolio selection},
	url = {https://doi.org/10.1007/s10479-021-04177-y},
	doi = {10.1007/s10479-021-04177-y},
	abstract = {Robust optimization (RO) models have attracted a lot of interest in the area of portfolio selection. RO extends the framework of traditional portfolio optimization models, incorporating uncertainty through a formal and analytical approach into the modeling process. Although several RO models have been proposed in the literature, comprehensive empirical assessments of their performance are rather lacking. The objective of this study is to fill in this gap in the literature. To this end, we consider different types of RO models based on popular risk measures and conduct an extensive comparative analysis of their performance using data from the US market during the period 2005–2020. For the analysis, two different robust versions of the mean–variance model are considered, together with robust models for conditional value-at-risk and the Omega ratio. The robust versions are compared against the nominal ones through various portfolio performance metrics, focusing on out-of-sample results.},
	language = {en},
	number = {3},
	urldate = {2024-09-18},
	journal = {Annals of Operations Research},
	author = {Georgantas, Antonios and Doumpos, Michalis and Zopounidis, Constantin},
	month = aug,
	year = {2024},
	keywords = {Robust optimization, Comparative analysis, Financial risk management, Portfolio selection},
	pages = {1205--1221},
	file = {Full Text PDF:/home/gabriel/Zotero/storage/2GF2D723/Georgantas et al. - 2024 - Robust optimization approaches for portfolio selection a comparative analysis.pdf:application/pdf},
}

@article{qiu_two-stage_2023,
	title = {Two-stage distributionally robust optimization-based coordinated scheduling of integrated energy system with electricity-hydrogen hybrid energy storage},
	volume = {8},
	issn = {2367-0983},
	url = {https://ieeexplore.ieee.org/abstract/document/10374394},
	doi = {10.1186/s41601-023-00308-8},
	abstract = {A coordinated scheduling model based on two-stage distributionally robust optimization (TSDRO) is proposed for integrated energy systems (IESs) with electricity-hydrogen hybrid energy storage. The scheduling problem of the IES is divided into two stages in the TSDRO-based coordinated scheduling model. The first stage addresses the day-ahead optimal scheduling problem of the IES under deterministic forecasting information, while the second stage uses a distributionally robust optimization method to determine the intraday rescheduling problem under high-order uncertainties, building upon the results of the first stage. The scheduling model also considers collaboration among the electricity, thermal, and gas networks, focusing on economic operation and carbon emissions. The flexibility of these networks and the energy gradient utilization of hydrogen units during operation are also incorporated into the model. To improve computational efficiency, the nonlinear formulations in the TSDRO-based coordinated scheduling model are properly linearized to obtain a Mixed-Integer Linear Programming model. The Column-Constraint Generation (C\&CG) algorithm is then employed to decompose the scheduling model into a master problem and subproblems. Through the iterative solution of the master problem and subproblems, an efficient analysis of the coordinated scheduling model is achieved. Finally, the effectiveness of the proposed TSDRO-based coordinated scheduling model is verified through case studies. The simulation results demonstrate that the proposed TSDRO-based coordinated scheduling model can effectively accomplish the optimal scheduling task while considering the uncertainty and flexibility of the system. Compared with traditional methods, the proposed TSDRO-based coordinated scheduling model can better balance conservativeness and robustness.},
	number = {2},
	urldate = {2024-09-18},
	journal = {Protection and Control of Modern Power Systems},
	author = {Qiu, Yibin and Li, Qi and Ai, Yuxuan and Chen, Weirong and Benbouzid, Mohamed and Liu, Shukui and Gao, Fei},
	month = apr,
	year = {2023},
	note = {Conference Name: Protection and Control of Modern Power Systems},
	keywords = {Computational modeling, Dynamic scheduling, Hydrogen, Integrated energy systems, Optimal scheduling, Processor scheduling, Simulation, Two-stage distributionally robust optimization, Uncertainty},
	pages = {1--14},
	file = {IEEE Xplore Full Text PDF:/home/gabriel/Zotero/storage/RY23QH6U/Qiu et al. - 2023 - Two-stage distributionally robust optimization-based coordinated scheduling of integrated energy sys.pdf:application/pdf},
}

@article{besbes_contextual_2023,
	title = {Contextual {Inverse} {Optimization}: {Offline} and {Online} {Learning}},
	issn = {0030-364X},
	shorttitle = {Contextual {Inverse} {Optimization}},
	url = {https://pubsonline.informs.org/doi/full/10.1287/opre.2021.0369},
	doi = {10.1287/opre.2021.0369},
	abstract = {We study the problems of offline and online contextual optimization with feedback information, where instead of observing the loss, we observe, after the fact, the optimal action an oracle with full knowledge of the objective function would have taken. We aim to minimize regret, which is defined as the difference between our losses and the ones incurred by an all-knowing oracle. In the offline setting, the decision maker has information available from past periods and needs to make one decision, whereas in the online setting, the decision maker optimizes decisions dynamically over time based a new set of feasible actions and contextual functions in each period. For the offline setting, we characterize the optimal minimax policy, establishing the performance that can be achieved as a function of the underlying geometry of the information induced by the data. In the online setting, we leverage this geometric characterization to optimize the cumulative regret. We develop an algorithm that yields the first regret bound for this problem that is logarithmic in the time horizon. Finally, we show via simulation that our proposed algorithms outperform previous methods from the literature. Supplemental Material: The online appendices are available at https://doi.org/10.1287/opre.2021.0369.},
	urldate = {2024-09-18},
	journal = {Operations Research},
	author = {Besbes, Omar and Fonseca, Yuri and Lobel, Ilan},
	month = aug,
	year = {2023},
	note = {Publisher: INFORMS},
	keywords = {Optimization, contextual optimization, data-driven decision making, imitation learning, inverse optimization, learning from revealed preferences, online optimization},
	file = {Full Text PDF:/home/gabriel/Zotero/storage/LR42RUFZ/Besbes et al. - 2023 - Contextual Inverse Optimization Offline and Online Learning.pdf:application/pdf},
}

@article{si_distributionally_2023,
	title = {Distributionally {Robust} {Batch} {Contextual} {Bandits}},
	volume = {69},
	issn = {0025-1909, 1526-5501},
	url = {https://pubsonline.informs.org/doi/10.1287/mnsc.2023.4678},
	doi = {10.1287/mnsc.2023.4678},
	abstract = {Policy learning using historical observational data are an important problem that has widespread applications. Examples include selecting offers, prices, or advertisements for consumers; choosing bids in contextual first-price auctions; and selecting medication based on patients’ characteristics. However, existing literature rests on the crucial assumption that the future environment where the learned policy will be deployed is the same as the past environment that has generated the data: an assumption that is often false or too coarse an approximation. In this paper, we lift this assumption and aim to learn a distributionally robust policy with incomplete observational data. We first present a policy evaluation procedure that allows us to assess how well the policy does under worst-case environment shift. We then establish a central limit theorem type guarantee for this proposed policy evaluation scheme. Leveraging this evaluation scheme, we further propose a novel learning algorithm that is able to learn a policy that is robust to adversarial perturbations and unknown covariate shifts with a performance guarantee based on the theory of uniform convergence. Finally, we empirically test the effectiveness of our proposed algorithm in synthetic datasets and demonstrate that it provides the robustness that is missing using standard policy learning algorithms. We conclude the paper by providing a comprehensive application of our methods in the context of a real-world voting data set.
            This paper was accepted by Hamid Nazerzadeh, data science.
            Funding: This work was supported by the National Science Foundation [Grant CCF-2106508] and the Air Force Office of Scientific Research [Award FA9550-20-1-0397]. Z. Zhou also gratefully acknowledges the JP Morgan AI Research Grant and the New York University’s Center for Global Economy and Business faculty research grant for support on this work. Additional support is gratefully acknowledged from the National Science Foundation [Grants 1915967 and 2118199].
            Supplemental Material: The data files and online appendix are available at https://doi.org/10.1287/mnsc.2023.4678 .},
	language = {en},
	number = {10},
	urldate = {2024-09-18},
	journal = {Management Science},
	author = {Si, Nian and Zhang, Fan and Zhou, Zhengyuan and Blanchet, Jose},
	month = oct,
	year = {2023},
	pages = {5772--5793},
	file = {si-et-al-2023-distributionally-robust-batch-contextual-bandits:/home/gabriel/Zotero/storage/L3DEFYZ8/si-et-al-2023-distributionally-robust-batch-contextual-bandits.pdf:application/pdf;Submitted Version:/home/gabriel/Zotero/storage/8WN6SPRQ/Si et al. - 2023 - Distributionally Robust Batch Contextual Bandits.pdf:application/pdf},
}

@article{esteban-perez_distributionally_2023,
	title = {Distributionally robust optimal power flow with contextual information},
	volume = {306},
	issn = {03772217},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0377221722008128},
	doi = {10.1016/j.ejor.2022.10.024},
	abstract = {In this paper, we develop a distributionally robust chance-constrained formulation of the Optimal Power Flow problem (OPF) whereby the system operator can leverage contextual information. For this purpose, we exploit an ambiguity set based on probability trimmings and optimal transport through which the dispatch solution is protected against the incomplete knowledge of the relationship between the OPF uncertainties and the context that is conveyed by a sample of their joint probability distribution. We provide a tractable reformulation of the proposed distributionally robust chance-constrained OPF problem under the popular conditional-value-at-risk approximation. By way of numerical experiments run on a modiﬁed IEEE-118 bus network with wind uncertainty, we show how the power system can substantially beneﬁt from taking into account the well-known statistical dependence between the point forecast of wind power outputs and its associated prediction error. Furthermore, the experiments conducted also reveal that the distributional robustness conferred on the OPF solution by our probability-trimmingsbased approach is superior to that bestowed by alternative approaches in terms of expected cost and system reliability.},
	language = {en},
	number = {3},
	urldate = {2024-09-18},
	journal = {European Journal of Operational Research},
	author = {Esteban-Pérez, Adrián and Morales, Juan M.},
	month = may,
	year = {2023},
	pages = {1047--1058},
	file = {PDF:/home/gabriel/Zotero/storage/ID2SNTFW/Esteban-Pérez and Morales - 2023 - Distributionally robust optimal power flow with contextual information.pdf:application/pdf},
}

@article{hu_contextual_2023,
	title = {Contextual {Stochastic} {Bilevel} {Optimization}},
	volume = {36},
	url = {https://proceedings.neurips.cc/paper_files/paper/2023/hash/f77d9409647c096789067c09455858a2-Abstract-Conference.html},
	language = {en},
	urldate = {2024-09-18},
	journal = {Advances in Neural Information Processing Systems},
	author = {Hu, Yifan and Wang, Jie and Xie, Yao and Krause, Andreas and Kuhn, Daniel},
	month = dec,
	year = {2023},
	pages = {78412--78434},
	file = {Full Text PDF:/home/gabriel/Zotero/storage/3INQWFC2/Hu et al. - 2023 - Contextual Stochastic Bilevel Optimization.pdf:application/pdf},
}

@inproceedings{cristian_discretization_2023,
	title = {A {Discretization} {Framework} for {Robust} {Contextual} {Stochastic} {Optimization}},
	url = {https://openreview.net/forum?id=ueTdErd5Ib},
	abstract = {We study contextual stochastic optimization problems. Optimization problems have uncertain parameters stemming from unknown, context-dependent, distributions. Due to the inherent uncertainty in these problems, one is often interested not only in minimizing expected cost, but also to be robust and protect against worst case scenarios. We propose a novel method that combines the learning stage with knowledge of the downstream optimization task. The method prescribes decisions which aim to maximize the likelihood that the cost is below a (user-controlled) threshold. The key idea is (1) to discretize the feasible region into subsets so that the uncertain objective function can be well approximated deterministically within each subset, and (2) devise a secondary optimization problem to prescribe decisions by integrating the individual approximations determined in step (1). We provide theoretical guarantees bounding the underlying regret of decisions proposed by our method. In addition, experimental results demonstrate that our approach is competitive in terms of average regret and yields more robust solutions than other methods proposed in the literature, including up to 20 times lower worst-case cost on a real-world electricity generation problem.},
	language = {en},
	urldate = {2024-09-18},
	author = {Cristian, Rares C. and Perakis, Georgia},
	month = oct,
	year = {2023},
	file = {Full Text PDF:/home/gabriel/Zotero/storage/X39KAMK3/Cristian and Perakis - 2023 - A Discretization Framework for Robust Contextual Stochastic Optimization.pdf:application/pdf},
}

@inproceedings{persak_contextual_2023,
	address = {Cham},
	title = {Contextual {Robust} {Optimisation} with {Uncertainty} {Quantification}},
	isbn = {978-3-031-33271-5},
	doi = {10.1007/978-3-031-33271-5_9},
	abstract = {We propose two pipelines for convex optimisation problems with uncertain parameters that aim to improve decision robustness by addressing the sensitivity of optimisation to parameter estimation. This is achieved by integrating uncertainty quantification (UQ) methods for supervised learning into the ambiguity sets for distributionally robust optimisation (DRO). The pipelines leverage learning to produce contextual/conditional ambiguity sets from side-information. The two pipelines correspond to different UQ approaches: i) explicitly predicting the conditional covariance matrix using deep ensembles (DEs) and Gaussian processes (GPs), and ii) sampling using Monte Carlo dropout, DEs, and GPs. We use i) to construct an ambiguity set by defining an uncertainty around the estimated moments to achieve robustness with respect to the prediction model. UQ ii) is used as an empirical reference distribution of a Wasserstein ball to enhance out of sample performance. DRO problems constrained with either ambiguity set are tractable for a range of convex optimisation problems. We propose data-driven ways of setting DRO robustness parameters motivated by either coverage or out of sample performance. These parameters provide a useful yardstick in comparing the quality of UQ between prediction models. The pipelines are computationally evaluated and compared with deterministic and unconditional approaches on simulated and real-world portfolio optimisation problems.},
	language = {en},
	booktitle = {Integration of {Constraint} {Programming}, {Artificial} {Intelligence}, and {Operations} {Research}},
	publisher = {Springer Nature Switzerland},
	author = {Peršak, Egon and Anjos, Miguel F.},
	editor = {Cire, Andre A.},
	year = {2023},
	keywords = {Distributionally Robust Optimisation, Prediction and Optimisation, Prescriptive Analytics, Uncertainty Quantification},
	pages = {124--132},
	file = {Full Text PDF:/home/gabriel/Zotero/storage/LSU8NXC9/Peršak and Anjos - 2023 - Contextual Robust Optimisation with Uncertainty Quantification.pdf:application/pdf},
}

@article{martinez-de-albeniz_here_2021,
	title = {Here comes the sun: {Fashion} goods retailing under weather fluctuations},
	volume = {294},
	issn = {03772217},
	shorttitle = {Here comes the sun},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0377221720301028},
	doi = {10.1016/j.ejor.2020.01.064},
	abstract = {The weather has been identiﬁed as an important driver of demand and constitutes a major risk for retailers, especially in goods for which usage is affected by weather conditions, such as soft drinks or fashion apparel. Speciﬁcally, weather variations change the propensity to visit the point of sales, because travel cost is affected by weather conditions; and they impact differently different product categories, because the reference utility in the mind of the consumer is affected by current weather. We empirically study these two impact dimensions at a large fashion apparel retailer. We ﬁnd that rain has a large effect on footfall, increasing it in shopping mall stores and decreasing it in street stores, which suggest that it is a ﬁrst-order factor for channel choice. Temperature has a milder effect on footfall. In contrast, temperature has a large impact on conversion, increasing sales of the “appropriate” categories: summer items are sold more under positive temperature shocks, and winter items less. Finally, although theory suggests that the weather should have a moderating effect on price sensitivity, we ﬁnd that it is unaffected by the weather. © 2020 Elsevier B.V. All rights reserved.},
	language = {en},
	number = {3},
	urldate = {2024-09-18},
	journal = {European Journal of Operational Research},
	author = {Martínez-de-Albéniz, Victor and Belkaid, Abdel},
	month = nov,
	year = {2021},
	pages = {820--830},
	file = {PDF:/home/gabriel/Zotero/storage/C66298TQ/Martínez-de-Albéniz and Belkaid - 2021 - Here comes the sun Fashion goods retailing under weather fluctuations.pdf:application/pdf},
}

@inproceedings{xu_stock_2018,
	address = {Melbourne, Australia},
	title = {Stock {Movement} {Prediction} from {Tweets} and {Historical} {Prices}},
	url = {https://aclanthology.org/P18-1183},
	doi = {10.18653/v1/P18-1183},
	abstract = {Stock movement prediction is a challenging problem: the market is highly stochastic, and we make temporally-dependent predictions from chaotic data. We treat these three complexities and present a novel deep generative model jointly exploiting text and price signals for this task. Unlike the case with discriminative or topic modeling, our model introduces recurrent, continuous latent variables for a better treatment of stochasticity, and uses neural variational inference to address the intractable posterior inference. We also provide a hybrid objective with temporal auxiliary to flexibly capture predictive dependencies. We demonstrate the state-of-the-art performance of our proposed model on a new stock movement prediction dataset which we collected.},
	urldate = {2024-09-18},
	booktitle = {Proceedings of the 56th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Xu, Yumo and Cohen, Shay B.},
	editor = {Gurevych, Iryna and Miyao, Yusuke},
	month = jul,
	year = {2018},
	pages = {1970--1979},
	file = {Full Text PDF:/home/gabriel/Zotero/storage/SR5LTZ54/Xu and Cohen - 2018 - Stock Movement Prediction from Tweets and Historical Prices.pdf:application/pdf},
}

@article{sadana_survey_2025,
	title = {A survey of contextual optimization methods for decision-making under uncertainty},
	volume = {320},
	issn = {03772217},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0377221724002200},
	doi = {10.1016/j.ejor.2024.03.020},
	abstract = {Recently there has been a surge of interest in operations research (OR) and the machine learning (ML) community in combining prediction algorithms and optimization techniques to solve decision-making problems in the face of uncertainty. This gave rise to the field of contextual optimization, under which data-driven procedures are developed to prescribe actions to the decision-maker that make the best use of the most recently updated information. A large variety of models and methods have been presented in both OR and ML literature under a variety of names, including data-driven optimization, prescriptive optimization, predictive stochastic programming, policy optimization, (smart) predict/estimate-then-optimize, decision-focused learning, (taskbased) end-to-end learning/forecasting/optimization, etc. This survey article unifies these models under the lens of contextual stochastic optimization, thus providing a general presentation of a large variety of problems. We identify three main frameworks for learning policies from data and present the existing models and methods under a uniform notation and terminology. Our objective with this survey is to both strengthen the general understanding of this active field of research and stimulate further theoretical and algorithmic advancements in integrating ML and stochastic programming.},
	language = {en},
	number = {2},
	urldate = {2024-09-18},
	journal = {European Journal of Operational Research},
	author = {Sadana, Utsav and Chenreddy, Abhilash and Delage, Erick and Forel, Alexandre and Frejinger, Emma and Vidal, Thibaut},
	month = jan,
	year = {2025},
	pages = {271--289},
	file = {PDF:/home/gabriel/Zotero/storage/ZY2RAVVP/Sadana et al. - 2025 - A survey of contextual optimization methods for decision-making under uncertainty.pdf:application/pdf},
}

@book{vanderbei_linear_2020,
	address = {Cham},
	edition = {5th ed},
	series = {International series in operations research \& management science; 285; v. 285},
	title = {Linear programming : foundations and extensions},
	isbn = {978-3-030-39415-8 3-030-39415-8},
	url = {https://search.ebscohost.com/login.aspx?direct=true&scope=site&db=nlebk&db=nlabk&AN=2545298},
	language = {English},
	publisher = {Springer},
	author = {Vanderbei, Robert J.},
	year = {2020},
	file = {Ebook:/home/gabriel/Zotero/storage/USDL5JHF/Linear Programming Foundations and Extensions.epub:application/epub+zip;PDF:/home/gabriel/Zotero/storage/KBCHSH8B/Linear Programming Foundations and Extensions.pdf:application/pdf},
}

@book{aharon_ben-tal_robust_2009,
	title = {Robust {Optimization}},
	isbn = {978-1-4008-3105-0},
	url = {http://ieeexplore.ieee.org/document/9452591},
	publisher = {Princeton University Press},
	author = {{Aharon Ben-Tal} and {Laurent El Ghaoui} and {Arkadi Nemirovski}},
	year = {2009},
	file = {PDF:/home/gabriel/Zotero/storage/NMPFAABF/Aharon Ben-Tal et al. - 2009 - Robust Optimization.pdf:application/pdf},
}

@article{geyer_convergence_1994,
	title = {On the {Convergence} of {Monte} {Carlo} {Maximum} {Likelihood} {Calculations}},
	volume = {56},
	issn = {00359246},
	url = {http://www.jstor.org/stable/2346044},
	abstract = {[Monte Carlo maximum likelihood for normalized families of distributions can be used for an extremely broad class of models. Given any family \{h$_{\textrm{θ}}$: θ ∈ Θ\} of non-negative integrable functions, maximum likelihood estimates in the family obtained by normalizing the functions to integrate to 1 can be approximated by Monte Carlo simulation, the only regularity conditions being a compactification of the parameter space such that the evaluation maps \${\textbackslash}theta {\textbackslash}mapsto h\_{\textbackslash}theta(x)\$ remain continuous. Then with probability 1 the Monte Carlo approximant to the log-likelihood hypoconverges to the exact log-likelihood, its maximizer converges to the exact maximum likelihood estimate, approximations to profile likelihoods hypoconverge to the exact profile and level sets of the approximate likelihood (support regions) converge to the exact sets (in Painlevé-Kuratowski set convergence). The same results hold when there are missing data if a Wald-type integrability condition is satisfied. Asymptotic normality of the Monte Carlo error and convergence of the Monte Carlo approximation to the observed Fisher information are also shown.]},
	number = {1},
	urldate = {2024-11-11},
	journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	author = {Geyer, Charles J.},
	year = {1994},
	note = {Publisher: [Royal Statistical Society, Oxford University Press]},
	pages = {261--274},
	file = {PDF:/home/gabriel/Zotero/storage/LGK3R9FM/Geyer - 1994 - On the Convergence of Monte Carlo Maximum Likelihood Calculations.pdf:application/pdf},
}

@article{mccormick_computability_1976,
	title = {Computability of global solutions to factorable nonconvex programs: {Part} {I} — {Convex} underestimating problems},
	volume = {10},
	issn = {1436-4646},
	url = {https://doi.org/10.1007/BF01580665},
	doi = {10.1007/BF01580665},
	abstract = {For nonlinear programming problems which are factorable, a computable procedure for obtaining tight underestimating convex programs is presented. This is used to exclude from consideration regions where the global minimizer cannot exist.},
	number = {1},
	journal = {Mathematical Programming},
	author = {McCormick, Garth P.},
	month = dec,
	year = {1976},
	pages = {147--175},
	file = {PDF:/home/gabriel/Zotero/storage/YEAF827F/McCormick - 1976 - Computability of global solutions to factorable nonconvex programs Part I — Convex underestimating.pdf:application/pdf},
}

@inproceedings{meyer_trilinear_2004,
	address = {Boston, MA},
	title = {Trilinear {Monomials} with {Positive} or {Negative} {Domains}: {Facets} of the {Convex} and {Concave} {Envelopes}},
	isbn = {978-1-4613-0251-3},
	abstract = {Approximations of the convex envelope of nonconvex functions play a central role in deterministic global optimization algorithms and the efficiency of these algorithms is highly infuenced by the tightness of these approximations. McCormick (1976), and AlKhayyal and Falk (1983) have shown how to construct the convex envelope of individual bilinear terms over a rectangular domain. Rikun (1997) has shown that the convex hull of multilinear monomials over a rectangular domain is polyhedral. Approximations of the convex envelope for higher order multilinear terms have been based on the recursive use of this bilinear construction. Only under very special circumstances, however, do these approximations yield the convex envelope itself. Explicit expressions defining the facets of the convex and concave envelopes for trilinear monomials, with positive or negative bounded domains for each variable, are derived in this paper.},
	booktitle = {Frontiers in {Global} {Optimization}},
	publisher = {Springer US},
	author = {Meyer, C. A. and Floudas, C. A.},
	editor = {Floudas, C. A. and Pardalos, Panos},
	year = {2004},
	pages = {327--352},
	file = {PDF:/home/gabriel/Zotero/storage/ITSUS5FC/Meyer and Floudas - 2004 - Trilinear Monomials with Positive or Negative Domains Facets of the Convex and Concave Envelopes.pdf:application/pdf},
}

@article{shaheen_carsharing_2006,
	title = {Carsharing in {North} {America}: {Market} {Growth}, {Current} {Developments}, and {Future} {Potential}},
	volume = {1986},
	issn = {0361-1981},
	url = {https://doi.org/10.1177/0361198106198600115},
	doi = {10.1177/0361198106198600115},
	abstract = {Carsharing provides members access to a fleet of autos for short-term use throughout the day, reducing the need for one or more personal vehicles. More than 10 years ago, carsharing operators began to appear in North America. Since 1994, 40 programs have been deployed?28 are operating in 36 urban areas, and 12 are now defunct. Another four are planned to launch in the next year. Carsharing growth potential in North America is examined on the basis of a survey of 26 existing organizations conducted from April to July 2005. Since the mid-1990s, the number of members and vehicles supported by carsharing in the United States and Canada has continued to grow, despite program closures. The three largest providers in the United States and Canada both support 94\% of the total carsharing membership. Growth potential in major metropolitan regions is estimated at 10\% of individuals over the age of 21 in North America. Although carsharing continues to gain popularity and market share, the authors conclude that increased carsharing education, impact evaluation, and supportive policy approaches, including mainstreaming carsharing as a transportation strategy, would aid the ongoing expansion and development of this alternative to private vehicle ownership.},
	number = {1},
	urldate = {2024-11-13},
	journal = {Transportation Research Record},
	author = {Shaheen, Susan A. and Cohen, Adam P. and Roberts, J. Darius},
	month = jan,
	year = {2006},
	note = {Publisher: SAGE Publications Inc},
	pages = {116--124},
	annote = {doi: 10.1177/0361198106198600115},
	file = {PDF:/home/gabriel/Zotero/storage/GL9L7C8R/Shaheen et al. - 2006 - Carsharing in North America Market Growth, Current Developments, and Future Potential.pdf:application/pdf},
}

@article{hernandez_customer_2010,
	title = {Customer behavior in electronic commerce: {The} moderating effect of e-purchasing experience},
	volume = {63},
	issn = {0148-2963},
	url = {https://www.sciencedirect.com/science/article/pii/S0148296309002161},
	doi = {10.1016/j.jbusres.2009.01.019},
	abstract = {This study analyzes the perceptions which induce customers to purchase over the Internet, testing the moderating effect of e-purchasing experience. We distinguish between two groups: (1) potential e-customers, who are considering making their first e-purchase, and (2) experienced e-customers, who have made at least one e-purchase and are thinking about continuing to do so. The perceptions that induce individuals to purchase online for the first time may not be the same as those that produce repurchasing behavior. Our findings demonstrate that customer behavior does not remain stable because the experience acquired from past e-purchases means that perceptions evolve. The relationships between perceptions of e-commerce change with purchasing experience, whilst the influence of Internet experience is stable for all users. The implications are especially interesting for e-commerce providers whose business models depend on e-customer behavior.},
	number = {9},
	journal = {Advances in Internet Consumer Behavior\& Marketing Strategy},
	author = {Hernández, Blanca and Jiménez, Julio and Martín, M. José},
	month = sep,
	year = {2010},
	keywords = {Adoption, E-commerce, E-purchasing behavior, E-purchasing experience, Repurchasing},
	pages = {964--971},
	file = {PDF:/home/gabriel/Zotero/storage/RN4JDZZI/Hernández et al. - 2010 - Customer behavior in electronic commerce The moderating effect of e-purchasing experience.pdf:application/pdf},
}

@misc{noauthor_sample_nodate,
	title = {The {Sample} {Average} {Approximation} {Method} for {Stochastic} {Discrete} {Optimization} {\textbar} {SIAM} {Journal} on {Optimization}},
	url = {https://epubs.siam.org/doi/10.1137/S1052623499363220},
	urldate = {2024-11-13},
	file = {The Sample Average Approximation Method for Stochastic Discrete Optimization | SIAM Journal on Optimization:/home/gabriel/Zotero/storage/Y7PQ8V5R/S1052623499363220.html:text/html},
}

@article{kleywegt_sample_2002,
	title = {The {Sample} {Average} {Approximation} {Method} for {Stochastic} {Discrete} {Optimization}},
	volume = {12},
	issn = {1052-6234},
	url = {https://doi.org/10.1137/S1052623499363220},
	doi = {10.1137/S1052623499363220},
	abstract = {In thispaper we study a Monte Carlo simulation--based approach to stochastic discrete optimization problems. The basic idea of such methods is that a random sample is generated and the expected value function is approximated by the corresponding sample average function. The obtained sample average optimization problem is solved, and the procedure is repeated several times until a stopping criterion is satisfied. We discuss convergence rates, stopping rules, and computational complexity of this procedure and present a numerical example for the stochastic knapsack problem.},
	number = {2},
	urldate = {2024-11-13},
	journal = {SIAM Journal on Optimization},
	author = {Kleywegt, Anton J. and Shapiro, Alexander and Homem-de-Mello, Tito},
	month = jan,
	year = {2002},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	pages = {479--502},
	annote = {doi: 10.1137/S1052623499363220},
	file = {PDF:/home/gabriel/Zotero/storage/K6UISYUL/Kleywegt et al. - 2002 - The Sample Average Approximation Method for Stochastic Discrete Optimization.pdf:application/pdf},
}

@misc{modos_mixed_2023,
	title = {Mixed {Integer} {Linear} {Programming}: {Introduction}},
	shorttitle = {Mixed {Integer} {Linear} {Programming}},
	url = {https://towardsdatascience.com/mixed-integer-linear-programming-1-bc0ef201ee87},
	abstract = {How to solve complex constrained optimisation problems having discrete variables},
	language = {en},
	urldate = {2024-11-28},
	journal = {Medium},
	author = {Módos, István},
	month = jan,
	year = {2023},
	file = {Snapshot:/home/gabriel/Zotero/storage/UJ8INHDE/mixed-integer-linear-programming-1-bc0ef201ee87.html:text/html},
}

@misc{noauthor_fileimage_nodate,
	title = {File:{Image} of updated estimators and envelopes.png - {Cornell} {University} {Computational} {Optimization} {Open} {Textbook} - {Optimization} {Wiki}},
	url = {https://optimization.cbe.cornell.edu/index.php?title=File:Image_of_updated_estimators_and_envelopes.png},
	urldate = {2024-11-29},
	file = {File\:Image of updated estimators and envelopes.png - Cornell University Computational Optimization Open Textbook - Optimization Wiki:/home/gabriel/Zotero/storage/YBTTF3BP/index.html:text/html},
}

@article{ciari_modeling_2014,
	title = {Modeling {Station}-{Based} and {Free}-{Floating} {Carsharing} {Demand}: {Test} {Case} {Study} for {Berlin}},
	volume = {2416},
	issn = {0361-1981},
	url = {https://doi.org/10.3141/2416-05},
	doi = {10.3141/2416-05},
	abstract = {Carsharing, in any form, is still growing around the world. One of the effects is the increasing number of cities in which multiple carsharing operators are competing. The carsharing industry has never been as competitive as it is now: the present is a good time for researchers to invest efforts in providing tools for the assessment and planning of carsharing programs. Nevertheless, efforts in this direction are still scarce, in particular for some of the newest forms in which carsharing has been implemented, such as free-floating carsharing. This paper reports on a study that made use of MATSim, an agent-based simulation software that had already been used to model station-based carsharing, to evaluate different carsharing scenarios for the city of Berlin. The main findings are the existing high potential to extend carsharing services further in Berlin and the apparent complementarity of station-based and free-floating carsharing. On the methodological level, the work introduces a new tool for the modeling of free-floating carsharing along with improvements of the previously existing station-based carsharing model.},
	number = {1},
	urldate = {2024-12-11},
	journal = {Transportation Research Record},
	author = {Ciari, Francesco and Bock, Benno and Balmer, Michael},
	month = jan,
	year = {2014},
	note = {Publisher: SAGE Publications Inc},
	pages = {37--47},
	annote = {doi: 10.3141/2416-05},
	file = {PDF:/home/gabriel/Zotero/storage/77258V5R/Ciari et al. - 2014 - Modeling Station-Based and Free-Floating Carsharing Demand Test Case Study for Berlin.pdf:application/pdf},
}

@techreport{cornuejols_uncapicitated_1983,
	title = {The uncapicitated facility location problem},
	institution = {Cornell University Operations Research and Industrial Engineering},
	author = {Cornuéjols, Gérard and Nemhauser, George and Wolsey, Laurence},
	year = {1983},
	file = {PDF:/home/gabriel/Zotero/storage/8BIYP3FL/Cornuéjols et al. - 1983 - The uncapicitated facility location problem.pdf:application/pdf},
}

@article{cheng_distributionally_2024,
	title = {Distributionally robust facility location with uncertain facility capacity and customer demand},
	volume = {122},
	journal = {Omega},
	author = {Cheng, Chun and Yu, Qinxiao and Adulyasak, Yossiri and Rousseau, Louis-Martin},
	year = {2024},
	note = {Publisher: Elsevier},
	pages = {102959},
	file = {PDF:/home/gabriel/Zotero/storage/VC5CPRNR/Cheng et al. - 2024 - Distributionally robust facility location with uncertain facility capacity and customer demand.pdf:application/pdf},
}

@article{liu_testing_2023,
	title = {Testing facility location and dynamic capacity planning for pandemics with demand uncertainty},
	volume = {304},
	number = {1},
	journal = {European journal of operational research},
	author = {Liu, Kanglin and Liu, Changchun and Xiang, Xi and Tian, Zhili},
	year = {2023},
	note = {Publisher: Elsevier},
	pages = {150--168},
	file = {PDF:/home/gabriel/Zotero/storage/QTFTWDNT/Liu et al. - 2023 - Testing facility location and dynamic capacity planning for pandemics with demand uncertainty.pdf:application/pdf},
}

@article{shehadeh_distributionally_2023,
	title = {Distributionally robust optimization approaches for a stochastic mobile facility fleet sizing, routing, and scheduling problem},
	volume = {57},
	number = {1},
	journal = {Transportation Science},
	author = {Shehadeh, Karmel S},
	year = {2023},
	note = {Publisher: INFORMS},
	pages = {197--229},
	file = {PDF:/home/gabriel/Zotero/storage/DQ2CKD9K/Shehadeh - 2023 - Distributionally robust optimization approaches for a stochastic mobile facility fleet sizing, routi.pdf:application/pdf},
}

@article{rodriguez_simulation-optimization_2021,
	title = {A simulation-optimization approach for the facility location and vehicle assignment problem for firefighters using a loosely coupled spatio-temporal arrival process},
	volume = {157},
	issn = {0360-8352},
	url = {https://www.sciencedirect.com/science/article/pii/S0360835221001467},
	doi = {10.1016/j.cie.2021.107242},
	abstract = {This work proposes a framework to aid the strategic decision making regarding the proper location of fire stations as well as their assignment of vehicles to improve emergency response. We present an iterative simulation–optimization approach that based on some precomputed utilization parameters updates the optimal location of vehicles and fire stations. First, we find an optimal solution by using a robust formulation of the Facility Location and Equipment Emplacement Technique with Expected Coverage (Robust FLEET-EXC) model, which maximizes demand considering vehicles’ utilization. Second, we use this solution as an input to a discrete event simulation model to compute utilization parameters. Then, if the obtained parameters deviate less than a desired error, the solution is maintained; otherwise, a new solution is computed with these new parameters. Additionally, the emergencies arrival process is modeled by a spatio-temporal sampling method that loosely couples a Kernel Density Estimator and a non-homogeneous non-renewal arrival process with a Markov-Mixture of Erlangs of Common Order model as base process. Then, the proposed robust model is compared to a deterministic FLEET model that does not account for vehicles’ availability, and the FLEET-EXC model with simulated utilization parameters. The main results show that the proposed spatio-temporal sampling method achieves a better representation of the emergency arrival process than those generally used in literature, and the resulting utilization parameters are statistically different than those produced by a Hypercube Queueing Model. On the other hand, the simulation–optimization approach that uses the Robust FLEET-EXC has the best performance, achieving the highest coverage of emergencies in 13 out of 15 experiments. Finally, this model is statistically better than the deterministic FLEET in all but one experiment, resulting in up to 6.42\% more coverage.},
	journal = {Computers \& Industrial Engineering},
	author = {Rodriguez, Sebastian A. and De la Fuente, Rodrigo A. and Aguayo, Maichel M.},
	month = jul,
	year = {2021},
	keywords = {Facility Location Problem, Simulation-optimization, Spatio-temporal simulation},
	pages = {107242},
	file = {PDF:/home/gabriel/Zotero/storage/DNNJDYE9/Rodriguez et al. - 2021 - A simulation-optimization approach for the facility location and vehicle assignment problem for fire.pdf:application/pdf},
}
